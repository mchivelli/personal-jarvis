<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant - Optimized</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 800px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 32px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .mic-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            margin: 40px 0;
        }

        .mic-button {
            width: 140px;
            height: 140px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 60px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            position: relative;
        }

        .mic-button:hover {
            transform: scale(1.05);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }

        .mic-button.processing {
            background: linear-gradient(135deg, #ffd89b 0%, #19547b 100%);
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); box-shadow: 0 10px 30px rgba(245, 87, 108, 0.4); }
            50% { transform: scale(1.05); box-shadow: 0 10px 50px rgba(245, 87, 108, 0.8); }
        }

        .status {
            text-align: center;
            margin: 20px 0;
            min-height: 30px;
            color: #666;
            font-size: 18px;
            font-weight: 500;
        }

        .conversation {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            min-height: 400px;
            max-height: 500px;
            overflow-y: auto;
            margin: 20px 0;
        }

        .message {
            margin: 15px 0;
            padding: 15px 20px;
            border-radius: 12px;
            max-width: 80%;
            line-height: 1.5;
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .message.user {
            background: #667eea;
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: white;
            color: #333;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .message .timestamp {
            font-size: 11px;
            opacity: 0.7;
            margin-top: 5px;
        }

        .metrics {
            display: flex;
            justify-content: space-around;
            margin: 20px 0;
            padding: 15px;
            background: #f0f0f0;
            border-radius: 10px;
        }

        .metric {
            text-align: center;
        }

        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #667eea;
        }

        .metric-label {
            font-size: 12px;
            color: #666;
            margin-top: 5px;
        }

        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 8px;
            background: #667eea;
            color: white;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.2s;
        }

        .btn:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .btn.secondary {
            background: #ccc;
            color: #333;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice Assistant</h1>
        <p class="subtitle">Optimized for low-latency conversation</p>

        <div class="mic-container">
            <button class="mic-button" id="micButton" onclick="toggleRecording()">
                üé§
            </button>
        </div>

        <div class="status" id="status">Press and hold to talk</div>

        <div class="metrics">
            <div class="metric">
                <div class="metric-value" id="transcriptionTime">0ms</div>
                <div class="metric-label">Transcription</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="aiTime">0ms</div>
                <div class="metric-label">AI Response</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="totalTime">0ms</div>
                <div class="metric-label">Total</div>
            </div>
        </div>

        <div class="conversation" id="conversation"></div>

        <div class="controls">
            <button class="btn secondary" onclick="clearConversation()">Clear History</button>
            <button class="btn" onclick="testConnection()">Test Connection</button>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let startTime;

        const micButton = document.getElementById('micButton');
        const status = document.getElementById('status');
        const conversation = document.getElementById('conversation');
        const transcriptionTimeEl = document.getElementById('transcriptionTime');
        const aiTimeEl = document.getElementById('aiTime');
        const totalTimeEl = document.getElementById('totalTime');

        // Push-to-talk: Press and hold
        micButton.addEventListener('mousedown', startRecording);
        micButton.addEventListener('mouseup', stopRecording);
        micButton.addEventListener('touchstart', startRecording);
        micButton.addEventListener('touchend', stopRecording);

        // Keyboard shortcut: Space bar
        document.addEventListener('keydown', (e) => {
            if (e.code === 'Space' && !isRecording) {
                e.preventDefault();
                startRecording();
            }
        });

        document.addEventListener('keyup', (e) => {
            if (e.code === 'Space' && isRecording) {
                e.preventDefault();
                stopRecording();
            }
        });

        async function startRecording() {
            if (isRecording) return;

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
                    ? 'audio/webm;codecs=opus' 
                    : 'audio/webm';

                mediaRecorder = new MediaRecorder(stream, { mimeType });
                audioChunks = [];
                startTime = Date.now();

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    await sendAudioToServer(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start(100);
                isRecording = true;
                micButton.classList.add('recording');
                micButton.textContent = 'üî¥';
                status.textContent = 'üé§ Recording... (release to send)';

            } catch (error) {
                console.error('Microphone error:', error);
                status.textContent = 'Error: Could not access microphone';
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                micButton.classList.remove('recording');
                micButton.classList.add('processing');
                micButton.textContent = '‚è≥';
                status.textContent = 'Processing...';
            }
        }

        async function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');

            const processingStart = Date.now();

            try {
                const res = await fetch('/api/voice', {
                    method: 'POST',
                    body: formData
                });

                const data = await res.json();
                const totalDuration = Date.now() - startTime;

                if (data.success) {
                    // Add user message
                    addMessage('user', data.transcript);

                    // Add assistant response
                    addMessage('assistant', data.response);

                    // Update metrics
                    const transcriptionDuration = processingStart - startTime;
                    const aiDuration = totalDuration - transcriptionDuration;
                    
                    transcriptionTimeEl.textContent = `${transcriptionDuration}ms`;
                    aiTimeEl.textContent = `${aiDuration}ms`;
                    totalTimeEl.textContent = `${totalDuration}ms`;

                    status.textContent = `‚úì Ready (${totalDuration}ms)`;
                } else {
                    status.textContent = `Error: ${data.error}`;
                }

            } catch (error) {
                console.error('Error:', error);
                status.textContent = 'Network error';
            } finally {
                micButton.classList.remove('processing');
                micButton.textContent = 'üé§';
                setTimeout(() => {
                    status.textContent = 'Press and hold to talk';
                }, 2000);
            }
        }

        function addMessage(type, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            
            const textDiv = document.createElement('div');
            textDiv.textContent = text;
            
            const timestamp = document.createElement('div');
            timestamp.className = 'timestamp';
            timestamp.textContent = new Date().toLocaleTimeString();
            
            messageDiv.appendChild(textDiv);
            messageDiv.appendChild(timestamp);
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function clearConversation() {
            conversation.innerHTML = '';
        }

        async function testConnection() {
            status.textContent = 'Testing connection...';
            try {
                const res = await fetch('/api/test');
                const data = await res.json();
                if (data.success) {
                    status.textContent = '‚úì Connection OK';
                } else {
                    status.textContent = '‚úó Connection failed';
                }
            } catch (error) {
                status.textContent = '‚úó Server not responding';
            }
            setTimeout(() => {
                status.textContent = 'Press and hold to talk';
            }, 2000);
        }

        // Auto-test on load
        window.addEventListener('load', () => {
            setTimeout(testConnection, 1000);
        });
    </script>
</body>
</html>
